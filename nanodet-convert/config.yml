# 模型转化相关的参数
model_parameters:
    # Caffe浮点网络数据模型文件
    #caffe_model: '../../../01_common/model_zoo/mapper/classification/mobilenet/mobilenet.caffemodel'
    # Caffe网络描述文件
    #prototxt: '../../../01_common/model_zoo/mapper/classification/mobilenet/mobilenet_deploy.prototxt'
    # onnx 模型文件
    onnx_model: "./nanodet.onnx"
    # 适用BPU架构
    march: "bayes"
    # 指定模型转换过程中是否输出各层的中间结果，如果为True，则输出所有层的中间输出结果，
    layer_out_dump: False
    # 日志文件的输出控制参数，
    # debug输出模型转换的详细信息
    # info只输出关键信息
    # warn输出警告和错误级别以上的信息
    log_level: 'debug'
    # 模型转换输出的结果的存放目录
    working_dir: 'model_output'
    # 模型转换输出的用于上板执行的模型文件的名称前缀
    output_model_file_prefix: 'nanodet_320x320'


# 模型输入相关参数, 若输入多个节点, 则应使用';'进行分隔, 使用默认缺省设置则写None
input_parameters:
    # (可不填) 模型输入的节点名称, 此名称应与模型文件中的名称一致, 否则会报错, 不填则会使用模型文件中的节点名称
    input_name: "data"
    # 网络实际执行时，输入给网络的数据格式，包括 nv12/rgb/bgr/yuv444/gray/featuremap,
    # 如果输入的数据为yuv444, 模型训练用的是bgr(NCHW)，则hb_mapper将自动插入YUV到BGR(NCHW)转化操作
    input_type_rt: 'bgr'
    # 转换后混合异构模型需要适配的输入数据排布，可设置为：NHWC/NCHW
    # 若input_type_rt配置为nv12，则此处参数不需要配置
    input_layout_rt: 'NCHW'
    # 网络训练时输入的数据格式，可选的值为rgb/bgr/gray/featuremap/yuv444
    input_type_train: 'bgr'
    # 网络训练时输入的数据排布, 可选值为 NHWC/NCHW
    input_layout_train: 'NCHW'
    # 模型网络的输入大小, 以'x'分隔, 不填则会使用模型文件中的网络输入大小，否则会覆盖模型文件中输入大小
    # 原始浮点模型的输入数据尺寸
    # input_shape: '1x3x224x224'

    # 网络实际执行时，输入给网络的batch_size, 默认值为1
    input_batch: 1
    # 网络输入的预处理方法，主要有以下几种：
    # no_preprocess 不做任何操作
    # data_mean 减去通道均值mean_value
    # data_scale 对图像像素乘以data_scale系数
    # data_mean_and_scale 减去通道均值后再乘以scale系数
    norm_type: 'no_preprocess'
    # 图像减去的均值, 如果是通道均值，value之间必须用空格分隔
    # mean_value: 0 0 0
    # 图像预处理缩放比例，如果是通道缩放比例，value之间必须用空格分隔
    # scale_value: 1  1  1

calibration_parameters:
    # 模型量化的参考图像的存放目录，图片格式支持JPEG、BMP等格式，输入的图片
    # 应该是使用的典型场景，一般是从测试集中选择20~100张图片，另外输入
    # 的图片要覆盖典型场景，不要是偏僻场景，如过曝光、饱和、模糊、纯黑、纯白等图片
    # 若有多个输入节点, 则应使用';'进行分隔
    cal_data_dir: './calibration_data'

    # 指定校准数据二进制文件的数据存储类型。
    cal_data_type: 'float32'

    # 如果输入的图片文件尺寸和模型训练的尺寸不一致时，并且preprocess_on为true，
    # 则将采用默认预处理方法(skimage resize)，
    # 将输入图片缩放或者裁减到指定尺寸，否则，需要用户提前把图片处理为训练时的尺寸
    preprocess_on: false
    # 模型量化的算法类型，支持kl、max、default、load，通常采用default即可满足要求, 若为QAT导出的模型, 则应选择load
    calibration_type: 'kl'
    
    # 指定是否针对每个channel进行校准
    per_channel: False

    # 指定输出节点的数据精度
    optimization: set_model_output_int16

# 编译器相关参数
compiler_parameters:
    # 编译策略，支持bandwidth和latency两种优化模式;
    # bandwidth以优化ddr的访问带宽为目标；
    # latency以优化推理时间为目标
    compile_mode: 'latency'
    # 设置debug为True将打开编译器的debug模式，能够输出性能仿真的相关信息，如帧率、DDR带宽占用等
    debug: False
    # 编译模型指定核数，不指定默认编译单核模型, 若编译双核模型，将下边注释打开即可
    # core_num: 2
    # 优化等级可选范围为O0~O3
    # O0不做任何优化, 编译速度最快，优化程度最低,
    # O1-O3随着优化等级提高，预期编译后的模型的执行速度会更快，但是所需编译时间也会变长。
    # 推荐用O2做最快验证
    optimize_level: 'O2'
    
    # 指定编译模型时的进程数
    jobs: 8